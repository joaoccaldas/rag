#!/bin/bash
# Ollama Service Auto-Start Script
# Automatically detects and starts Ollama with available models

echo "ğŸ” Checking Ollama service status..."

# Check if Ollama is running
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollama service is already running"
    
    # List available models
    echo "ğŸ“‹ Available models:"
    curl -s http://localhost:11434/api/tags | grep -o '"name":"[^"]*"' | cut -d'"' -f4
    
    exit 0
fi

echo "ğŸš€ Starting Ollama service..."

# Start Ollama service in background
if command -v ollama > /dev/null 2>&1; then
    # Start service
    nohup ollama serve > ollama.log 2>&1 &
    
    echo "â³ Waiting for service to start..."
    sleep 5
    
    # Check if service started
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama service started successfully!"
        
        # Check for models
        models=$(curl -s http://localhost:11434/api/tags | grep -o '"name":"[^"]*"' | cut -d'"' -f4)
        
        if [ -z "$models" ]; then
            echo "ğŸ“¥ No models found. Pulling recommended model..."
            echo "ğŸ”„ This may take several minutes..."
            
            # Try to pull a lightweight model
            if ollama pull llama3.1:8b; then
                echo "âœ… Model llama3.1:8b installed successfully!"
            elif ollama pull llama3:8b; then
                echo "âœ… Model llama3:8b installed successfully!"
            elif ollama pull llama2:7b; then
                echo "âœ… Model llama2:7b installed successfully!"
            else
                echo "âŒ Failed to pull any models. Please manually install a model:"
                echo "   ollama pull llama3.1:8b"
            fi
        else
            echo "ğŸ“‹ Available models:"
            echo "$models"
        fi
    else
        echo "âŒ Failed to start Ollama service"
        echo "ğŸ“‹ Check the log file: ollama.log"
        exit 1
    fi
else
    echo "âŒ Ollama not found. Please install from https://ollama.ai"
    echo "ğŸ“¥ Download: https://ollama.ai/download"
    exit 1
fi

echo "ğŸ‰ Setup complete! Ollama is ready at http://localhost:11434"
